{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Gene Array Report**\n",
    "\n",
    "Author: Jonathan Yin\n",
    "\n",
    "## **Data Overview**\n",
    "\n",
    "The dataset consists of 33 CSV files representing well slides, organized into 11 sets with each set performed in triplicate.\n",
    "\n",
    "#### Slide Design\n",
    "\n",
    "Each slide contains 384 wells arranged in a 16×24 formation, with 320 unique genes and 64 controls. The genes are located in the center 16×20 region, while the controls occupy the outer 2 columns on each side. There are 4 types of controls used: \"rf\", \"fit1\", \"bscl2\", and \"rfnotDL\".\n",
    "\n",
    "![image](plots/ArrayDesign.png)\n",
    "\n",
    "#### Measurements\n",
    "\n",
    "For measurement purposes, each well on each slide was captured 7 times, with each capture generating a 130-dimensional feature vector (X1, X2, ..., X130).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Cleaning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "slidefiles_dir = Path(\"data/SlideFiles\")\n",
    "csv_files = os.listdir(slidefiles_dir)\n",
    "\n",
    "raw_df = pd.DataFrame()\n",
    "for csv_file in csv_files:\n",
    "    file_path = slidefiles_dir / csv_file\n",
    "    raw_df = pd.concat([raw_df, pd.read_csv(file_path)])\n",
    "\n",
    "raw_df.drop(columns=[\"type.f\"], inplace=True)\n",
    "raw_df = raw_df.sort_values(by=[\"slide\", \"well\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Aggregation\n",
    "\n",
    "First, we aggregate the 7 well measurements to produce a 130-dimensional feature vector for each well. We do this by taking the median of the 7 measurements across the 130 features. This makes the well measurements more robust to noise and easier to analyze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import METADATA_COLS, FEATURE_COLS\n",
    "\n",
    "df = raw_df.groupby([\"slide\", \"well\"]).agg(\n",
    "    {\n",
    "        **{col: \"median\" for col in FEATURE_COLS},\n",
    "        **{col: \"first\" for col in METADATA_COLS if col not in [\"well\", \"slide\"]},\n",
    "    }\n",
    ")\n",
    "# Reset index to make slide and well regular columns again and re-order columns to match raw_df\n",
    "df = df.reset_index()\n",
    "df = df[raw_df.columns.tolist()]\n",
    "df = df.sort_values(by=[\"slide\", \"well\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Slide-level Differences\n",
    "\n",
    "To be able to compare wells across different slides, we need to account for potential systematic differences between slides.\n",
    "\n",
    "Examining the distribution of feature vectors for gene wells within a slide reveals that each of the 130 dimensions approximately follows a normal distribution.\n",
    "\n",
    "Since genes are randomly assigned to a set, we can reasonably assume that the underlying distribution of these feature vectors should be consistent across all slides. Any systematic differences observed between slides are likely due to technical variations rather than biological differences.\n",
    "\n",
    "To normalize these slide-specific effects, we can apply z-score normalization on a per-slide basis: for each feature dimension, we subtract the mean and divide by the standard deviation of the gene wells' measurements within that slide. This standardization procedure allows for more meaningful comparisons of wells across different slides by removing slide-specific biases. Furthermore, it makes it easier to compare the various dimensions of the feature vectors since now they are all on the same scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_utils import plot_feature_histograms\n",
    "\n",
    "for slide_number in df[\"slide\"].unique()[:1]:\n",
    "    plot_feature_histograms(\n",
    "        df[(df[\"slide\"] == slide_number) & (df[\"type\"] == \"gene\")],\n",
    "        f\"Feature Histograms for Gene Wells in Slide {slide_number}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slide_number in df[\"slide\"].unique():\n",
    "    slide_indices = df[\"slide\"] == slide_number\n",
    "    gene_indices = slide_indices & (df[\"type\"] == \"gene\")\n",
    "\n",
    "    if gene_indices.any():\n",
    "        # Calculate mean and standard deviation for feature columns\n",
    "        gene_means = df.loc[gene_indices, FEATURE_COLS].mean()\n",
    "        gene_stds = df.loc[gene_indices, FEATURE_COLS].std()\n",
    "\n",
    "        # Normalize all rows for this slide by subtracting mean and dividing by std\n",
    "        for feature in FEATURE_COLS:\n",
    "            df.loc[slide_indices, feature] = (\n",
    "                df.loc[slide_indices, feature] - gene_means[feature]\n",
    "            ) / gene_stds[feature]\n",
    "    else:\n",
    "        print(f\"Warning: No gene rows found for slide {slide_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Approach: Negative Control-based Normalization\n",
    "\n",
    "Another approach to normalize slide-level differences is to use negative control (rf) wells as reference points. Since these wells should be identical across slides, any variations likely represent technical differences rather than biological ones.\n",
    "\n",
    "This approach involves:\n",
    "\n",
    "1. Computing a slide-specific baseline by taking the median of the 24 rf wells on each slide (creating a 130-dimensional reference vector per slide)\n",
    "2. Establishing a global baseline by calculating the median across all 792 rf wells (33 slides × 24 wells)\n",
    "3. Normalizing each well's measurements by subtracting the slide-specific baseline and dividing by a measure of variability\n",
    "\n",
    "The z-score normalization approach described above is preferable to the negative control-based normalization for several reasons:\n",
    "\n",
    "1. **More robust statistics**: By using all gene wells on a slide (320 wells), we have a larger sample size for calculating means and standard deviations compared to using only 24 rf wells, resulting in more stable normalization parameters.\n",
    "\n",
    "2. **Simpler implementation**: The z-score approach requires fewer computational steps and doesn't need to establish both slide-specific and global baselines.\n",
    "\n",
    "3. **Established statistical properties**: Z-score normalization produces features with zero mean and unit variance, which is beneficial for many downstream methods that assume standardized inputs.\n",
    "\n",
    "4. **Direct comparability**: After z-score normalization, features across all slides are immediately comparable without additional adjustment steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplicate Aggregation\n",
    "\n",
    "Finally, we aggregate the triplicate slides by taking the median of the feature vectors for each well position. This produces a 130-dimensional feature vector for each well position in the set. This leaves us with 11 slides of 384 wells, each with a 130-dimensional feature vector.\n",
    "\n",
    "While it is possible to further aggregate the 64 control wells on each slide to produce a single 130-dimensional feature vector for each control, we choose not to do so because we are mainly interested in the gene wells and retaining well-level information is useful downstream to validate our outlier detection methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby([\"set\", \"well\"]).agg(\n",
    "    {\n",
    "        **{col: \"median\" for col in FEATURE_COLS},\n",
    "        **{\n",
    "            col: \"first\" for col in METADATA_COLS if col not in [\"well\", \"set\", \"slide\"]\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "df = df.reset_index()\n",
    "columns_to_keep = [col for col in raw_df.columns.tolist() if col != \"slide\"]\n",
    "df = df[columns_to_keep]\n",
    "df = df.sort_values(by=[\"set\", \"well\"])\n",
    "df.to_csv(\"data/cleaned_gene_array_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Outlier Detection**\n",
    "\n",
    "First, to get a sense of what we are looking for, we compare the distribution of the gene wells, which are mostly negative hits, to the distribution of the bscl2 wells, which are known to be positive controls. Across a majority of the 130 features, there appears to be a difference in the distribution of the gene wells and the bscl2 wells. However, it's unclear if all positive hits will differ in the same way as the bscl2 wells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_utils import compare_feature_histograms\n",
    "\n",
    "compare_feature_histograms(\n",
    "    df,\n",
    "    \"gene\",\n",
    "    \"bscl2\",\n",
    "    \"Feature Histograms for bscl2 and gene wells\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Detection Methods\n",
    "\n",
    "We'll use two different methods to detect outliers in our dataset:\n",
    "\n",
    "1. **Euclidean Distance**: This method calculates the distance between a well's feature vector and the mean feature vector of all gene wells in the 130-dimensional feature space. Wells with larger Euclidean distances from the mean are considered potential outliers. This approach assumes that outliers are points that are far from the center of the data distribution.\n",
    "\n",
    "2. **Isolation Forest**: This algorithm isolates observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature. Outliers require fewer splits to be isolated, resulting in shorter paths in the trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we use a euclidean distance threshold to detect outliers. Euclidean distance assigns equal weight to all dimensions of the feature vector, which is acceptable here because we have already normalized the feature vectors to have zero mean and unit variance. To compute distance, we use the mean of the gene wells as the reference point. We then choose a distance threshold that yields 100 genes wells to investigate out of 3520 total gene wells.\n",
    "\n",
    "We see that this method correctly identifies 99.4% of the bscl2 wells as outliers and 99.4% of the rfnotDL well as outliers as well. It falsely classified 5.7% of rf wells as outliers despite it being a known negative control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "df_data = df[FEATURE_COLS].values\n",
    "gene_data = df[df[\"type\"] == \"gene\"][FEATURE_COLS].values\n",
    "\n",
    "gene_mean = np.mean(gene_data, axis=0)\n",
    "\n",
    "df[\"euclidean_distance\"] = df.apply(\n",
    "    lambda row: distance.euclidean(row[FEATURE_COLS], gene_mean),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the threshold using only the gene data\n",
    "threshold = np.percentile(\n",
    "    df[df[\"type\"] == \"gene\"][\"euclidean_distance\"], (1 - (100 / 3520)) * 100\n",
    ")\n",
    "\n",
    "# Create a new column indicating whether each sample exceeds the threshold\n",
    "df[\"euclidean_outlier\"] = df[\"euclidean_distance\"] > threshold\n",
    "\n",
    "outlier_summary = df.groupby(\"type\")[\"euclidean_outlier\"].agg([\"count\", \"sum\"])\n",
    "outlier_summary[\"percentage\"] = (\n",
    "    outlier_summary[\"sum\"] / outlier_summary[\"count\"]\n",
    ") * 100\n",
    "print(outlier_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(df[df[\"type\"] == \"gene\"][\"euclidean_distance\"], bins=50)\n",
    "plt.title(\"Euclidean Distance of Gene Wells\")\n",
    "plt.axvline(\n",
    "    threshold,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"Threshold\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the isolation forest method to detect outliers. We fit the isolation forest on the gene wells and then use the model to predict on all wells. It identified 239 gene wells as potential outliers.\n",
    "\n",
    "The isolation forest correctly identified 99.4% of the bscl2 wells as outliers and 100% of the rfnotDL wells as outliers, which is a nearly identical true positive rate compared to the euclidean distance method. However, it falsely classified 8.7% of rf wells as outliers, which is a worse false positive rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "clf = IsolationForest(random_state=425).fit(gene_data)\n",
    "outlier_scores = clf.predict(df[FEATURE_COLS].values)\n",
    "\n",
    "df[\"isolation_forest_outlier\"] = outlier_scores == -1\n",
    "\n",
    "outlier_summary = df.groupby(\"type\")[\"isolation_forest_outlier\"].agg([\"count\", \"sum\"])\n",
    "outlier_summary[\"percentage\"] = (\n",
    "    outlier_summary[\"sum\"] / outlier_summary[\"count\"]\n",
    ") * 100\n",
    "print(outlier_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, we have exactly 100 gene wells that are identified as outliers by both methods. That is, every well identified as an outlier by the euclidean distance threshold was also deemed an outlier by the isolation forest method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"both_outlier\"] = df[\"isolation_forest_outlier\"] & df[\"euclidean_outlier\"]\n",
    "\n",
    "outlier_gene_wells = df[df[\"both_outlier\"] & (df[\"type\"] == \"gene\")]\n",
    "print(len(outlier_gene_wells))\n",
    "outlier_gene_wells[[col for col in METADATA_COLS if col != \"slide\"]].to_csv(\n",
    "    \"data/outlier_gene_wells.csv\", index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "Finally, we perform PCA and UMAP dimensionality reduction on the gene wells to visualize the outliers in a lower-dimensional space in comparison to the non-outlier wells. This offers a sanity check to ensure that the outliers are indeed potentially interesting to investigate.\n",
    "\n",
    "To interactively explore the visualizations, open the html files `plots/pca_3d_scatter.html` and `plots/umap_3d_scatter.html`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dimension_reduction_df(\n",
    "    transformed_data,\n",
    "    n_components,\n",
    "    prefix,\n",
    "    df,\n",
    "):\n",
    "    transformed_data = transformed_data[:, :n_components]\n",
    "    columns = [f\"{prefix}{i + 1}\" for i in range(n_components)]\n",
    "    result_df = pd.DataFrame(transformed_data, columns=columns)\n",
    "\n",
    "    # Add metadata columns from original DataFrame\n",
    "    for col in df.columns:\n",
    "        if col not in FEATURE_COLS:\n",
    "            result_df[col] = df[col].values\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "Here we see that the outlier gene wells do appear to be either at the edges of the gene well cluster or part of other clusters, such as the bscl2 or rfnotDL clusters. Furthermore, as expected, the positive control wells are clusters together and separately from the gene well cluster while the rf wells are clusters alongside the gene wells.\n",
    "\n",
    "![image](plots/pca_3d_scatter.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from plotting_utils import plot_3d_scatter, plot_pca_explained_variance\n",
    "\n",
    "\n",
    "def perform_pca(X_scaled):\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    return X_pca, pca\n",
    "\n",
    "\n",
    "X_pca, pca = perform_pca(df_data)\n",
    "\n",
    "plot_pca_explained_variance(pca)\n",
    "\n",
    "pca_df = create_dimension_reduction_df(\n",
    "    X_pca,\n",
    "    3,\n",
    "    \"PC\",\n",
    "    df,\n",
    ")\n",
    "\n",
    "pca_fig = plot_3d_scatter(\n",
    "    pca_df,\n",
    "    \"PC1\",\n",
    "    \"PC2\",\n",
    "    \"PC3\",\n",
    "    title=\"3D PCA Projection\",\n",
    "    type_col=\"type\",\n",
    "    outlier_col=\"both_outlier\",\n",
    "    filename=\"plots/pca_3d_scatter\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP\n",
    "\n",
    "In the UMAP embedding, we see very similar phenomena as in the PCA plot.\n",
    "\n",
    "![image](plots/umap_3d_scatter.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "\n",
    "def perform_umap(data, n_components=3, n_neighbors=200, min_dist=0.8):\n",
    "    \"\"\"Perform UMAP dimensionality reduction on the input data.\"\"\"\n",
    "    umap_model = UMAP(\n",
    "        n_components=n_components,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "    )\n",
    "    umap_result = umap_model.fit_transform(data)\n",
    "    return umap_result\n",
    "\n",
    "\n",
    "# Perform UMAP and create DataFrame\n",
    "X_umap = perform_umap(df_data)\n",
    "umap_df = create_dimension_reduction_df(X_umap, 3, \"UMAP\", df)\n",
    "\n",
    "# Plot UMAP results\n",
    "umap_fig = plot_3d_scatter(\n",
    "    umap_df,\n",
    "    \"UMAP1\",\n",
    "    \"UMAP2\",\n",
    "    \"UMAP3\",\n",
    "    title=\"3D UMAP Projection\",\n",
    "    type_col=\"type\",\n",
    "    outlier_col=\"both_outlier\",\n",
    "    filename=\"plots/umap_3d_scatter\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
