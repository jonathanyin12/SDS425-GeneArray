{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"all_sets_df.csv\")\n",
    "gene_df = df[df[\"type\"] == \"gene\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_COLS = [\"type\", \"row\", \"col\", \"well\", \"set\", \"type.f\", \"slide\"]\n",
    "\n",
    "# Get feature columns (all columns except metadata)\n",
    "FEATURE_COLS = [col for col in df.columns if col not in METADATA_COLS]\n",
    "\n",
    "TREATMENTS = set([\"gene\"])\n",
    "CONTROLS = set(df[\"type\"]) - TREATMENTS\n",
    "print(f\"Unique types: {set(df['type'])}\")  # Unique types\n",
    "print(f\"Treatments: {TREATMENTS}\")\n",
    "print(f\"Controls: {CONTROLS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Extract the data for wells with type 'rf' (negative control)\n",
    "gene_data = gene_df[FEATURE_COLS].values\n",
    "\n",
    "# Calculate the mean vector and covariance matrix of the reference data\n",
    "gene_mean = np.mean(gene_data, axis=0)\n",
    "gene_cov = np.cov(gene_data, rowvar=False)\n",
    "\n",
    "\n",
    "# Function to calculate Mahalanobis distance\n",
    "def calculate_mahalanobis(x, mean, cov):\n",
    "    \"\"\"Calculate the Mahalanobis distance between x and the distribution defined by mean and cov.\"\"\"\n",
    "    return distance.mahalanobis(x, mean, np.linalg.inv(cov))\n",
    "\n",
    "\n",
    "# Calculate Mahalanobis distance for each row in the dataframe\n",
    "print(\"Calculating Mahalanobis distance for each sample...\")\n",
    "df[\"mahalanobis_distance\"] = df.apply(\n",
    "    lambda row: calculate_mahalanobis(row[FEATURE_COLS], gene_mean, gene_cov), axis=1\n",
    ")\n",
    "\n",
    "# Calculate the 95th percentile threshold using only the gene data\n",
    "gene_distances = df[df[\"type\"] == \"gene\"][\"mahalanobis_distance\"]\n",
    "threshold = np.percentile(gene_distances, 100 - (100 / 3520) * 100)\n",
    "\n",
    "# Create a new column indicating whether each sample exceeds the threshold\n",
    "df[\"mahalanobis_outlier\"] = df[\"mahalanobis_distance\"] > threshold\n",
    "\n",
    "# Count how many samples of each type exceed the threshold\n",
    "threshold_summary = df.groupby(\"type\")[\"mahalanobis_outlier\"].agg([\"count\", \"sum\"])\n",
    "threshold_summary[\"percentage\"] = (\n",
    "    threshold_summary[\"sum\"] / threshold_summary[\"count\"]\n",
    ") * 100\n",
    "print(threshold_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "clf = IsolationForest(random_state=0, contamination=100 / 3520).fit(\n",
    "    gene_df[FEATURE_COLS].values\n",
    ")\n",
    "outlier_scores = clf.predict(df[FEATURE_COLS].values)\n",
    "\n",
    "# outlier_scores = IsolationForest(\n",
    "#     random_state=0, contamination=((176) * 2 + 100) / 3520\n",
    "# ).fit_predict(df[FEATURE_COLS].values)\n",
    "\n",
    "df[\"isolation_forest_outlier\"] = outlier_scores == -1\n",
    "\n",
    "# Count how many samples of each type exceed the threshold\n",
    "threshold_summary = df.groupby(\"type\")[\"isolation_forest_outlier\"].agg([\"count\", \"sum\"])\n",
    "threshold_summary[\"percentage\"] = (\n",
    "    threshold_summary[\"sum\"] / threshold_summary[\"count\"]\n",
    ") * 100\n",
    "print(threshold_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors\n",
    "\n",
    "\n",
    "# Detect outliers using LocalOutlierFactor\n",
    "outlier_scores = sklearn.neighbors.LocalOutlierFactor(contamination=0.15).fit_predict(\n",
    "    df[FEATURE_COLS].values\n",
    ")\n",
    "\n",
    "df[\"lof_outlier\"] = outlier_scores == -1\n",
    "\n",
    "# Count how many samples of each type exceed the threshold\n",
    "threshold_summary = df.groupby(\"type\")[\"lof_outlier\"].agg([\"count\", \"sum\"])\n",
    "threshold_summary[\"percentage\"] = (\n",
    "    threshold_summary[\"sum\"] / threshold_summary[\"count\"]\n",
    ") * 100\n",
    "print(threshold_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def plot_3d_scatter(\n",
    "    df,\n",
    "    x_col,\n",
    "    y_col,\n",
    "    z_col,\n",
    "    type_col=\"type\",\n",
    "    outlier_col=None,\n",
    "    title=\"3D Scatter Plot\",\n",
    "    hover_data=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a 3D scatter plot colored by type using customdata for hover info.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas DataFrame\n",
    "        The data to plot\n",
    "    x_col, y_col, z_col : str\n",
    "        Column names for the x, y, and z axes\n",
    "    type_col : str, default=\"type\"\n",
    "        Column name for the categorical variable to color by\n",
    "    title : str, default=\"3D Scatter Plot\"\n",
    "        Title for the plot\n",
    "    hover_data : list, default=None\n",
    "        List of column names to include in hover information (e.g., [\"row\", \"col\", \"well\"])\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Default hover data if none provided\n",
    "    if hover_data is None:\n",
    "        hover_data = []\n",
    "\n",
    "    # Always include type_col in hover_data if not already present\n",
    "    if type_col not in hover_data:\n",
    "        hover_data = [type_col] + hover_data\n",
    "\n",
    "    # Construct hovertemplate string dynamically\n",
    "    ht = \"\"\n",
    "    for i, col_name in enumerate(hover_data):\n",
    "        # Use the corresponding customdata index for each column name\n",
    "        ht += f\"<b>{col_name}</b>: %{{customdata[{i}]}}<br>\"\n",
    "    ht += \"<extra></extra>\"  # Hide the default trace info box like 'trace 0'\n",
    "\n",
    "    # Get a consistent color for this type_name\n",
    "    # Get the default plotly colors\n",
    "    import plotly.express as px\n",
    "\n",
    "    # Create a mapping from type to color using Dark2 and Set2 color palettes\n",
    "    type_names = df[type_col].unique()\n",
    "    dark2_colors = px.colors.qualitative.Dark2  # For outliers\n",
    "    set2_colors = px.colors.qualitative.Set2  # For non-outliers\n",
    "\n",
    "    # Create two color mappings for each type - one for outliers and one for non-outliers\n",
    "    type_colors = {}\n",
    "    type_colors_outlier = {}\n",
    "\n",
    "    for i, t in enumerate(type_names):\n",
    "        dark2_idx = i % len(dark2_colors)\n",
    "        set2_idx = i % len(set2_colors)\n",
    "        type_colors[t] = set2_colors[set2_idx]  # Regular points\n",
    "        type_colors_outlier[t] = dark2_colors[dark2_idx]  # Outlier points\n",
    "\n",
    "    # Plot points for each type with different colors\n",
    "    for type_name in df[type_col].unique():\n",
    "        if outlier_col is not None:\n",
    "            # Create separate traces for outliers and non-outliers\n",
    "\n",
    "            for is_outlier in [True, False]:\n",
    "                mask = (df[type_col] == type_name) & (df[outlier_col] == is_outlier)\n",
    "                if mask.any():  # Only create trace if there are points\n",
    "                    df_filtered = df[mask]\n",
    "                    customdata_values = df_filtered[hover_data].values\n",
    "\n",
    "                    name = f\"{type_name} (Outlier)\" if is_outlier else str(type_name)\n",
    "\n",
    "                    trace = go.Scatter3d(\n",
    "                        x=df_filtered[x_col],\n",
    "                        y=df_filtered[y_col],\n",
    "                        z=df_filtered[z_col],\n",
    "                        mode=\"markers\",\n",
    "                        name=name,\n",
    "                        marker=dict(\n",
    "                            size=6,\n",
    "                            opacity=1 if is_outlier else 0.8,\n",
    "                            symbol=\"diamond\" if is_outlier else \"circle\",\n",
    "                            line=dict(\n",
    "                                width=1 if is_outlier else 0,\n",
    "                                color=\"black\",  # Keep border color consistent\n",
    "                            ),\n",
    "                            color=type_colors_outlier[type_name]\n",
    "                            if is_outlier\n",
    "                            else type_colors[type_name],\n",
    "                        ),\n",
    "                        legendgroup=name,  # Group traces by type_name\n",
    "                        customdata=customdata_values,\n",
    "                        hovertemplate=ht,\n",
    "                    )\n",
    "\n",
    "                    fig.add_trace(trace)\n",
    "        else:\n",
    "            # Just create traces by type\n",
    "            mask = df[type_col] == type_name\n",
    "            df_filtered = df[mask]\n",
    "            customdata_values = df_filtered[hover_data].values\n",
    "\n",
    "            trace = go.Scatter3d(\n",
    "                x=df_filtered[x_col],\n",
    "                y=df_filtered[y_col],\n",
    "                z=df_filtered[z_col],\n",
    "                mode=\"markers\",\n",
    "                name=str(type_name),  # Ensure name is a string\n",
    "                marker=dict(size=6, opacity=0.7),\n",
    "                customdata=customdata_values,\n",
    "                hovertemplate=ht,\n",
    "            )\n",
    "\n",
    "            fig.add_trace(trace)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            xaxis_title=x_col,\n",
    "            yaxis_title=y_col,\n",
    "            zaxis_title=z_col,\n",
    "        ),\n",
    "        width=1200,\n",
    "        height=1200,\n",
    "        showlegend=True,\n",
    "    )\n",
    "    fig.show()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def save_plot(fig, filename):\n",
    "    \"\"\"Save the plot as HTML.\"\"\"\n",
    "    fig.write_html(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_dimension_reduction_df(\n",
    "    transformed_data,\n",
    "    n_components,\n",
    "    prefix=\"UMAP\",\n",
    "    original_df=None,\n",
    "    type_col=\"type\",\n",
    "    hover_data=None,\n",
    "):\n",
    "    \"\"\"Create a DataFrame from UMAP results with optional metadata from original DataFrame.\"\"\"\n",
    "    transformed_data = transformed_data[:, :n_components]\n",
    "    columns = [f\"{prefix}{i + 1}\" for i in range(n_components)]\n",
    "    result_df = pd.DataFrame(transformed_data, columns=columns)\n",
    "\n",
    "    if original_df is not None:\n",
    "        # Add type column if it exists\n",
    "        if type_col in original_df.columns:\n",
    "            result_df[type_col] = original_df[type_col]\n",
    "        else:\n",
    "            raise ValueError(f\"type_col '{type_col}' not found in original DataFrame.\")\n",
    "\n",
    "        # Add hover data columns if specified\n",
    "        if hover_data is not None:\n",
    "            for col in hover_data:\n",
    "                if col in original_df.columns:\n",
    "                    result_df[col] = original_df[col]\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        f\"hover_data column '{col}' not found in original DataFrame.\"\n",
    "                    )\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def preprocess_data(df, feature_cols):\n",
    "    \"\"\"Standardize the feature data.\"\"\"\n",
    "    X = df[feature_cols]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X, X_scaled\n",
    "\n",
    "\n",
    "X, X_scaled = preprocess_data(df, FEATURE_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def perform_pca(X_scaled):\n",
    "    \"\"\"Perform PCA and return transformed data and PCA object.\"\"\"\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    return X_pca, pca\n",
    "\n",
    "\n",
    "def plot_explained_variance(pca):\n",
    "    \"\"\"Plot the cumulative explained variance ratio.\"\"\"\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        range(1, len(explained_variance_ratio) + 1), cumulative_variance_ratio, \"bo-\"\n",
    "    )\n",
    "    plt.xlabel(\"Number of Components\")\n",
    "    plt.ylabel(\"Cumulative Explained Variance Ratio\")\n",
    "    plt.title(\"PCA Explained Variance Ratio\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return cumulative_variance_ratio\n",
    "\n",
    "\n",
    "HOVER_COLS = [\n",
    "    \"row\",\n",
    "    \"col\",\n",
    "    \"well\",\n",
    "    \"set\",\n",
    "    \"mahalanobis_outlier\",\n",
    "    \"isolation_forest_outlier\",\n",
    "]\n",
    "\n",
    "X_pca, pca = perform_pca(X_scaled)\n",
    "plot_explained_variance(pca)\n",
    "\n",
    "\n",
    "# Create PCA DataFrame and plot\n",
    "pca_df = create_dimension_reduction_df(\n",
    "    X_pca, 3, \"PC\", df, type_col=\"type\", hover_data=HOVER_COLS\n",
    ")\n",
    "\n",
    "pca_fig = plot_3d_scatter(\n",
    "    pca_df,\n",
    "    \"PC1\",\n",
    "    \"PC2\",\n",
    "    \"PC3\",\n",
    "    title=\"3D PCA Projection\",\n",
    "    hover_data=HOVER_COLS,  # Pass the list of *additional* columns to show\n",
    "    type_col=\"type\",  # Specify the column used for coloring/grouping\n",
    "    outlier_col=\"isolation_forest_outlier\",\n",
    ")\n",
    "\n",
    "save_plot(pca_fig, \"pca_3d_plot.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UMAP for dimensionality reduction\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "\n",
    "def perform_umap(data, n_components=3, random_state=42, n_neighbors=100, min_dist=0.8):\n",
    "    \"\"\"Perform UMAP dimensionality reduction on the input data.\"\"\"\n",
    "    umap_model = UMAP(\n",
    "        n_components=n_components,\n",
    "        random_state=random_state,\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "    )\n",
    "    umap_result = umap_model.fit_transform(data)\n",
    "    return umap_result, umap_model\n",
    "\n",
    "\n",
    "# Perform UMAP and create DataFrame\n",
    "X_umap, umap_model = perform_umap(X_scaled)\n",
    "umap_df = create_dimension_reduction_df(X_umap, 3, \"UMAP\", df, hover_data=HOVER_COLS)\n",
    "\n",
    "# Plot UMAP results\n",
    "umap_fig = plot_3d_scatter(\n",
    "    umap_df,\n",
    "    \"UMAP1\",\n",
    "    \"UMAP2\",\n",
    "    \"UMAP3\",\n",
    "    title=\"3D UMAP Projection\",\n",
    "    type_col=\"type\",\n",
    "    hover_data=HOVER_COLS,\n",
    "    outlier_col=\"isolation_forest_outlier\",\n",
    ")\n",
    "\n",
    "save_plot(umap_fig, \"umap_3d_plot.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
